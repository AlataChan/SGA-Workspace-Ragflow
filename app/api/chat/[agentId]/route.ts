import { NextRequest, NextResponse } from 'next/server'
import { logger } from '@/lib/utils/simple-logger'

// åˆ›å»ºæµå¼å“åº”
function createStreamResponse(difyResponse: Response) {
  const encoder = new TextEncoder()

  const stream = new ReadableStream({
    async start(controller) {
      const reader = difyResponse.body?.getReader()
      if (!reader) {
        controller.close()
        return
      }

      try {
        while (true) {
          const { done, value } = await reader.read()
          if (done) break

          // è§£æDifyçš„SSEæ•°æ®
          const chunk = new TextDecoder().decode(value)
          const lines = chunk.split('\n')

          for (const line of lines) {
            if (line.startsWith('data: ')) {
              const data = line.slice(6)
              if (data === '[DONE]') {
                controller.close()
                return
              }

              try {
                const parsed = JSON.parse(data)
                // è½¬å‘ç»™å‰ç«¯
                controller.enqueue(encoder.encode(`data: ${JSON.stringify(parsed)}\n\n`))
              } catch (e) {
                // å¿½ç•¥è§£æé”™è¯¯
              }
            }
          }
        }
      } catch (error) {
        logger.error('æµå¼å“åº”é”™è¯¯', { error: error.message })
        controller.error(error)
      } finally {
        controller.close()
      }
    }
  })

  return new Response(stream, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
    }
  })
}

// åˆ›å»ºæ¨¡æ‹Ÿæµå¼å“åº”
function createMockStreamResponse(agentName: string, message: string, userId: string, conversationId?: string) {
  const encoder = new TextEncoder()

  const mockResponse = `æ‚¨å¥½ï¼æˆ‘æ˜¯${agentName}ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚

æ‚¨åˆšæ‰è¯´ï¼š"${message}"

è®©æˆ‘ä¸ºæ‚¨è¯¦ç»†ä»‹ç»ä¸€ä¸‹æˆ‘çš„åŠŸèƒ½å’Œç‰¹è‰²ï¼š

ğŸ¤– **æ™ºèƒ½å¯¹è¯èƒ½åŠ›**
æˆ‘å…·å¤‡å¼ºå¤§çš„è‡ªç„¶è¯­è¨€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œå¯ä»¥è¿›è¡Œæµç•…çš„å¤šè½®å¯¹è¯ï¼Œç†è§£ä¸Šä¸‹æ–‡ï¼Œå¹¶æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›å¤ã€‚

ğŸ“Š **ä¸“ä¸šçŸ¥è¯†æ”¯æŒ**
æˆ‘æ‹¥æœ‰å¹¿æ³›çš„çŸ¥è¯†åº“ï¼Œæ¶µç›–ç§‘æŠ€ã€å•†ä¸šã€æ•™è‚²ã€ç”Ÿæ´»ç­‰å¤šä¸ªé¢†åŸŸï¼Œå¯ä»¥ä¸ºæ‚¨æä¾›ä¸“ä¸šçš„å»ºè®®å’Œè§£ç­”ã€‚

âš¡ **å®æ—¶æµå¼è¾“å‡º**
æ­£å¦‚æ‚¨ç°åœ¨çœ‹åˆ°çš„ï¼Œæˆ‘æ”¯æŒå®æ—¶æµå¼è¾“å‡ºï¼Œè®©å¯¹è¯æ›´åŠ è‡ªç„¶æµç•…ï¼Œå°±åƒçœŸäººæ‰“å­—ä¸€æ ·ã€‚

ğŸ”§ **ä¼ä¸šçº§åº”ç”¨**
æˆ‘ä¸“ä¸ºä¼ä¸šç¯å¢ƒè®¾è®¡ï¼Œæ”¯æŒå®šåˆ¶åŒ–é…ç½®ï¼Œå¯ä»¥é›†æˆåˆ°å„ç§ä¸šåŠ¡ç³»ç»Ÿä¸­ã€‚

ç”¨æˆ·ID: ${userId}
ä¼šè¯ID: ${conversationId || 'demo-conversation'}

æ„Ÿè°¢æ‚¨çš„ä½¿ç”¨ï¼æœ‰ä»€ä¹ˆå…¶ä»–é—®é¢˜å—ï¼Ÿ`

  const stream = new ReadableStream({
    async start(controller) {
      const messageId = `mock-msg-${Date.now()}`

      // æŒ‰è¯ç»„å‘é€ï¼Œæ›´å¥½çš„æµå¼æ•ˆæœ - ä½¿ç”¨OpenAIæ ¼å¼
      const words = mockResponse.split(' ')

      for (let i = 0; i < words.length; i++) {
        const word = words[i] + (i < words.length - 1 ? ' ' : '')

        // ä½¿ç”¨OpenAIæ ¼å¼çš„æµå¼å“åº”
        const openaiFormat = {
          id: messageId,
          object: 'chat.completion.chunk',
          created: Math.floor(Date.now() / 1000),
          model: 'mock-model',
          choices: [{
            index: 0,
            delta: {
              content: word
            },
            finish_reason: null
          }]
        }

        controller.enqueue(encoder.encode(`data: ${JSON.stringify(openaiFormat)}\n\n`))

        // æŒ‰è¯ç»„å»¶è¿Ÿï¼Œæ›´è‡ªç„¶çš„æ‰“å­—æ•ˆæœ
        await new Promise(resolve => setTimeout(resolve, 100))
      }

      // å‘é€ç»“æŸäº‹ä»¶
      const endFormat = {
        id: messageId,
        object: 'chat.completion.chunk',
        created: Math.floor(Date.now() / 1000),
        model: 'mock-model',
        choices: [{
          index: 0,
          delta: {},
          finish_reason: 'stop'
        }]
      }
      controller.enqueue(encoder.encode(`data: ${JSON.stringify(endFormat)}\n\n`))

      controller.enqueue(encoder.encode('data: [DONE]\n\n'))
      controller.close()
    }
  })

  return new Response(stream, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
    }
  })
}

// ç®€åŒ–çš„æ™ºèƒ½ä½“é…ç½®
const AGENT_CONFIGS = {
  'demo-agent-1': {
    name: 'GPTåŠ©æ‰‹',
    platform: 'openai',
    apiUrl: process.env.OPENAI_API_URL || 'https://api.openai.com/v1/chat/completions',
    apiKey: process.env.OPENAI_API_KEY || '',
    model: 'gpt-3.5-turbo'
  },
  'demo-agent-2': {
    name: 'Difyæ™ºèƒ½ä½“',
    platform: 'dify',
    apiUrl: 'http://192.144.232.60/v1/chat-messages',
    apiKey: 'hvTuW1NrJZ5JDjdQ', // ä½¿ç”¨ä½ æä¾›çš„çœŸå®token
    appId: 'hvTuW1NrJZ5JDjdQ',
    appType: 'agent'
  },
  'demo-agent-3': {
    name: 'ä»£ç åŠ©æ‰‹',
    platform: 'openai',
    apiUrl: process.env.OPENAI_API_URL || 'https://api.openai.com/v1/chat/completions',
    apiKey: process.env.OPENAI_API_KEY || '',
    model: 'gpt-4'
  },
  'demo-agent-4': {
    name: 'æ–‡æ¡£åŠ©æ‰‹',
    platform: 'dify',
    apiUrl: 'http://192.144.232.60/v1/chat-messages',
    apiKey: 'app-P0zICVDnPuLSteB4iM7SClQi',
    appId: 'app-P0zICVDnPuLSteB4iM7SClQi'
  }
}

export async function POST(
  request: NextRequest,
  { params }: { params: Promise<{ agentId: string }> }
) {
  try {
    const { agentId } = await params
    const body = await request.json()

    // æ”¯æŒä¸¤ç§è¯·æ±‚æ ¼å¼ï¼š
    // 1. æ—§æ ¼å¼ï¼š{ message, userId, conversationId }
    // 2. æ–°æ ¼å¼ï¼š{ messages, config, userId }
    let message: string
    let userId: string
    let conversationId: string | undefined

    if (body.messages && Array.isArray(body.messages)) {
      // NextChaté£æ ¼çš„è¯·æ±‚æ ¼å¼
      const lastMessage = body.messages[body.messages.length - 1]
      message = lastMessage?.content || ''
      userId = body.userId || 'demo-user'
      conversationId = body.conversationId
    } else {
      // æ—§çš„è¯·æ±‚æ ¼å¼
      message = body.message || ''
      userId = body.userId || 'demo-user'
      conversationId = body.conversationId
    }

    logger.info('èŠå¤©è¯·æ±‚', {
      agentId,
      userId,
      userIdType: typeof userId,
      messageLength: message?.length,
      conversationId,
      requestFormat: body.messages ? 'nextchat' : 'legacy'
    })

    // è·å–æ™ºèƒ½ä½“é…ç½®
    const agentConfig = AGENT_CONFIGS[agentId as keyof typeof AGENT_CONFIGS]
    if (!agentConfig) {
      return NextResponse.json(
        { error: 'æ™ºèƒ½ä½“ä¸å­˜åœ¨' },
        { status: 404 }
      )
    }

    // ä¸ºäº†æ¼”ç¤ºï¼Œç›´æ¥è¿”å›æ¨¡æ‹Ÿæµå¼å“åº”
    logger.info('è¿”å›æ¨¡æ‹Ÿæµå¼å“åº”', { agentName: agentConfig.name })
    return createMockStreamResponse(agentConfig.name, message, userId, conversationId)

  } catch (error) {
    logger.error('èŠå¤©APIé”™è¯¯', { error: error.message })
    return NextResponse.json(
      { error: 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯' },
      { status: 500 }
    )
  }
}

// Dify APIè°ƒç”¨
async function callDifyAPI(config: any, message: string, userId: string, conversationId?: string) {
  try {
    // å¦‚æœæ²¡æœ‰é…ç½®APIå¯†é’¥ï¼Œè¿”å›æ¨¡æ‹Ÿæµå¼å“åº”
    if (!config.apiKey) {
      logger.info('ä½¿ç”¨æ¨¡æ‹ŸDifyæµå¼å“åº”')
      const mockAnswer = `è¿™æ˜¯æ¥è‡ª${config.name}çš„æ¨¡æ‹Ÿå“åº”ï¼š\n\næ‚¨è¯´ï¼š"${message}"\n\næˆ‘æ˜¯åŸºäºDifyå¹³å°çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œç›®å‰å¤„äºæ¼”ç¤ºæ¨¡å¼ã€‚è¦å¯ç”¨çœŸå®çš„AIå¯¹è¯ï¼Œè¯·åœ¨ç¯å¢ƒå˜é‡ä¸­é…ç½®DIFY_API_KEYå’ŒDIFY_API_URLã€‚\n\nç”¨æˆ·ID: ${userId}`
      return createMockStreamResponse(config.name, mockAnswer, userId, conversationId)
    }

    // å¯¹äºAgent Chatï¼Œä½¿ç”¨streamingæ¨¡å¼
    const requestBody = {
      inputs: {},
      query: message,
      response_mode: 'streaming',
      conversation_id: conversationId,
      user: userId
    }

    logger.info('å‘é€Difyè¯·æ±‚', {
      url: config.apiUrl,
      body: requestBody,
      hasApiKey: !!config.apiKey
    })

    const response = await fetch(config.apiUrl, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${config.apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      const errorText = await response.text()
      logger.error('Dify APIé”™è¯¯', {
        status: response.status,
        error: errorText
      })

      // å¦‚æœæ˜¯Agent Chatä¸æ”¯æŒstreamingçš„é”™è¯¯ï¼Œå°è¯•blockingæ¨¡å¼
      if (errorText.includes('does not support streaming mode')) {
        logger.info('Agent Chatä¸æ”¯æŒstreamingï¼Œå°è¯•blockingæ¨¡å¼')
        return callDifyBlocking(config, message, userId, conversationId)
      }

      throw new Error(`Dify APIé”™è¯¯: ${response.status} - ${errorText}`)
    }

    // è¿”å›Difyæµå¼å“åº”
    return createDifyStreamResponse(response)

  } catch (error) {
    logger.error('Dify APIè°ƒç”¨å¤±è´¥', {
      error: error.message,
      stack: error.stack,
      config: {
        url: config.apiUrl,
        hasApiKey: !!config.apiKey
      }
    })
    throw error
  }
}

// OpenAI APIè°ƒç”¨
async function callOpenAIAPI(config: any, message: string, userId: string) {
  try {
    // å¦‚æœæ²¡æœ‰é…ç½®APIå¯†é’¥ï¼Œè¿”å›æ¨¡æ‹Ÿæµå¼å“åº”
    if (!config.apiKey) {
      logger.info('ä½¿ç”¨æ¨¡æ‹ŸOpenAIæµå¼å“åº”')
      const mockAnswer = `è¿™æ˜¯æ¥è‡ª${config.name}çš„æ¨¡æ‹Ÿå“åº”ï¼š\n\næ‚¨è¯´ï¼š"${message}"\n\næˆ‘æ˜¯åŸºäºOpenAIçš„æ™ºèƒ½åŠ©æ‰‹ï¼Œç›®å‰å¤„äºæ¼”ç¤ºæ¨¡å¼ã€‚è¦å¯ç”¨çœŸå®çš„AIå¯¹è¯ï¼Œè¯·åœ¨ç¯å¢ƒå˜é‡ä¸­é…ç½®OPENAI_API_KEYã€‚\n\nç”¨æˆ·ID: ${userId}`
      return createMockStreamResponse(config.name, mockAnswer, userId)
    }

    const requestBody = {
      model: config.model,
      messages: [
        {
          role: 'system',
          content: `ä½ æ˜¯${config.name}ï¼Œä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚ç”¨æˆ·IDæ˜¯${userId}ã€‚`
        },
        {
          role: 'user',
          content: message
        }
      ],
      temperature: 0.7,
      max_tokens: 1000
    }

    const response = await fetch(config.apiUrl, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${config.apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      throw new Error(`OpenAI APIé”™è¯¯: ${response.status}`)
    }

    const data = await response.json()
    logger.info('OpenAI APIå“åº”æˆåŠŸ')

    // è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
    return NextResponse.json({
      answer: data.choices[0].message.content,
      conversation_id: `openai-conv-${Date.now()}`,
      message_id: `openai-msg-${Date.now()}`
    })

  } catch (error) {
    logger.error('OpenAI APIè°ƒç”¨å¤±è´¥', { error: error.message })
    throw error
  }
}

// è·å–æ™ºèƒ½ä½“ä¿¡æ¯
export async function GET(
  request: NextRequest,
  { params }: { params: Promise<{ agentId: string }> }
) {
  try {
    const { agentId } = await params
    const agentConfig = AGENT_CONFIGS[agentId as keyof typeof AGENT_CONFIGS]
    
    if (!agentConfig) {
      return NextResponse.json(
        { error: 'æ™ºèƒ½ä½“ä¸å­˜åœ¨' },
        { status: 404 }
      )
    }

    return NextResponse.json({
      id: agentId,
      name: agentConfig.name,
      platform: agentConfig.platform,
      status: agentConfig.apiKey ? 'active' : 'demo'
    })

  } catch (error) {
    logger.error('è·å–æ™ºèƒ½ä½“ä¿¡æ¯å¤±è´¥', { error: error.message })
    return NextResponse.json(
      { error: 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯' },
      { status: 500 }
    )
  }
}

// Dify blockingæ¨¡å¼è°ƒç”¨ï¼ˆç”¨äºAgent Chatï¼‰
async function callDifyBlocking(config: any, message: string, userId: string, conversationId?: string) {
  try {
    const requestBody = {
      inputs: {},
      query: message,
      response_mode: 'blocking',
      conversation_id: conversationId,
      user: userId
    }

    logger.info('å‘é€Dify blockingè¯·æ±‚', {
      url: config.apiUrl,
      body: requestBody,
      hasApiKey: !!config.apiKey
    })

    const response = await fetch(config.apiUrl, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${config.apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(requestBody)
    })

    const responseText = await response.text()
    logger.info('Dify blockingå“åº”', {
      status: response.status,
      response: responseText.substring(0, 500)
    })

    if (!response.ok) {
      throw new Error(`Dify APIé”™è¯¯: ${response.status} - ${responseText}`)
    }

    const data = JSON.parse(responseText)
    logger.info('Dify blocking APIå“åº”æˆåŠŸ', {
      messageId: data.message_id,
      conversationId: data.conversation_id
    })

    // è¿”å›æ ‡å‡†æ ¼å¼çš„å“åº”
    return NextResponse.json({
      answer: data.answer,
      conversation_id: data.conversation_id,
      message_id: data.message_id,
      metadata: data.metadata || {},
      created_at: data.created_at
    })

  } catch (error) {
    logger.error('Dify blocking APIè°ƒç”¨å¤±è´¥', {
      error: error.message,
      stack: error.stack
    })
    throw error
  }
}

// åˆ›å»ºDifyæµå¼å“åº” - çœŸæ­£çš„æµå¼è¾“å‡º
function createDifyStreamResponse(response: Response) {
  const encoder = new TextEncoder()

  const stream = new ReadableStream({
    async start(controller) {
      const reader = response.body?.getReader()
      if (!reader) {
        controller.close()
        return
      }

      const decoder = new TextDecoder()
      let buffer = ''

      try {
        while (true) {
          const { done, value } = await reader.read()

          if (done) {
            // å‘é€ç»“æŸæ ‡è®°
            controller.enqueue(encoder.encode('data: [DONE]\n\n'))
            controller.close()
            break
          }

          // è§£ç æ•°æ®
          const chunk = decoder.decode(value, { stream: true })
          buffer += chunk

          // æŒ‰è¡Œåˆ†å‰²å¤„ç†
          const lines = buffer.split('\n')
          buffer = lines.pop() || '' // ä¿ç•™æœ€åä¸€è¡Œï¼ˆå¯èƒ½ä¸å®Œæ•´ï¼‰

          for (const line of lines) {
            if (line.trim() === '') continue

            try {
              // å¤„ç†Difyçš„SSEæ ¼å¼
              if (line.startsWith('data: ')) {
                const jsonStr = line.slice(6).trim()
                if (jsonStr) {
                  const data = JSON.parse(jsonStr)

                  // è½¬æ¢ä¸ºOpenAIæ ¼å¼çš„æµå¼å“åº”
                  if (data.event === 'message' && data.answer) {
                    const openaiFormat = {
                      id: data.message_id || 'dify-msg',
                      object: 'chat.completion.chunk',
                      created: Math.floor(Date.now() / 1000),
                      model: 'dify-agent',
                      choices: [{
                        index: 0,
                        delta: {
                          content: data.answer
                        },
                        finish_reason: null
                      }]
                    }

                    controller.enqueue(encoder.encode(`data: ${JSON.stringify(openaiFormat)}\n\n`))
                  }

                  // å¤„ç†æ¶ˆæ¯æ›¿æ¢äº‹ä»¶
                  if (data.event === 'message_replace' && data.answer) {
                    const openaiFormat = {
                      id: data.message_id || 'dify-msg',
                      object: 'chat.completion.chunk',
                      created: Math.floor(Date.now() / 1000),
                      model: 'dify-agent',
                      choices: [{
                        index: 0,
                        delta: {
                          content: data.answer
                        },
                        finish_reason: null
                      }]
                    }

                    controller.enqueue(encoder.encode(`data: ${JSON.stringify(openaiFormat)}\n\n`))
                  }

                  // å¤„ç†ç»“æŸäº‹ä»¶
                  if (data.event === 'message_end') {
                    const openaiFormat = {
                      id: data.message_id || 'dify-msg',
                      object: 'chat.completion.chunk',
                      created: Math.floor(Date.now() / 1000),
                      model: 'dify-agent',
                      choices: [{
                        index: 0,
                        delta: {},
                        finish_reason: 'stop'
                      }]
                    }

                    controller.enqueue(encoder.encode(`data: ${JSON.stringify(openaiFormat)}\n\n`))
                  }
                }
              }
            } catch (e) {
              console.warn('è§£æDify SSEæ•°æ®å¤±è´¥:', e)
            }
          }
        }
      } catch (error) {
        console.error('Difyæµå¼å“åº”å¤„ç†é”™è¯¯:', error)
        controller.error(error)
      }
    }
  })

  return new Response(stream, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS',
      'Access-Control-Allow-Headers': 'Content-Type, Authorization',
    },
  })
}
