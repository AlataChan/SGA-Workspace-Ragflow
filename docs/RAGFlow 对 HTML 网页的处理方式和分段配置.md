è®©æˆ‘æŸ¥çœ‹ä¸€ä¸‹ RAGFlow å¯¹ HTML ç½‘é¡µçš„å¤„ç†æ–¹å¼å’Œåˆ†æ®µé…ç½®ï¼š

æ ¹æ®ä»£ç åˆ†æï¼Œæˆ‘æ¥è¯¦ç»†è¯´æ˜ **HTML ç½‘é¡µçš„çŸ¥è¯†åº“é…ç½®å’ŒçŸ¥è¯†å›¾è°±æå–æ–¹æ¡ˆ**ï¼š

---

## ğŸ“‹ HTML ç½‘é¡µçŸ¥è¯†åº“é…ç½®æ–¹æ¡ˆ

### 1ï¸âƒ£ **æ”¯æŒ HTML çš„åˆ†æ®µæ–¹æ³•ï¼ˆChunk Methodï¼‰**

RAGFlow ä¸­æ”¯æŒ HTML æ–‡ä»¶çš„åˆ†æ®µæ–¹æ³•æœ‰ **2 ç§**ï¼š

| åˆ†æ®µæ–¹æ³• | æ˜¯å¦æ”¯æŒ HTML | ç‰¹ç‚¹ | æ¨èåœºæ™¯ |
|---------|--------------|------|---------|
| **Naive** âœ… | âœ… æ”¯æŒ | æ™ºèƒ½åˆ†æ®µï¼ŒåŸºäº token æ•°é‡å’Œåˆ†éš”ç¬¦ | **æ¨èç”¨äºç½‘é¡µ** |
| **Book** âœ… | âœ… æ”¯æŒ | æŒ‰ç« èŠ‚ç»“æ„åˆ†æ®µ | é€‚åˆé•¿ç¯‡ç½‘é¡µæ–‡æ¡£ |

---

### 2ï¸âƒ£ **æ¨èé…ç½®ï¼šNaive æ–¹æ³•**

#### **ä¸ºä»€ä¹ˆé€‰æ‹© Naiveï¼Ÿ**

1. **ä¸“é—¨çš„ HTML è§£æå™¨**ï¼šä½¿ç”¨ `RAGFlowHtmlParser`ï¼ˆ`deepdoc/parser/html_parser.py`ï¼‰
2. **æ™ºèƒ½æ¸…ç†**ï¼šè‡ªåŠ¨åˆ é™¤ `<style>`ã€`<script>`ã€æ³¨é‡Šç­‰æ— ç”¨å†…å®¹
3. **ç»“æ„åŒ–åˆ†æ®µ**ï¼šè¯†åˆ« HTML æ ‡ç­¾ç»“æ„ï¼ˆh1-h6, p, div, table ç­‰ï¼‰
4. **çµæ´»é…ç½®**ï¼šå¯è°ƒæ•´ token æ•°é‡ã€åˆ†éš”ç¬¦ç­‰å‚æ•°

#### **é…ç½®å‚æ•°**

````python path=rag/app/naive.py mode=EXCERPT
parser_config = {
    "chunk_token_num": 512,        # æ¯ä¸ªåˆ†æ®µçš„ token æ•°é‡
    "delimiter": "\n!?ã€‚ï¼›ï¼ï¼Ÿ",    # åˆ†éš”ç¬¦
    "layout_recognize": "DeepDOC", # å¸ƒå±€è¯†åˆ«æ–¹æ³•
    "analyze_hyperlink": True      # æ˜¯å¦åˆ†æè¶…é“¾æ¥
}
````

---

### 3ï¸âƒ£ **HTML è§£æå™¨å·¥ä½œåŸç†**

````python path=deepdoc/parser/html_parser.py mode=EXCERPT
class RAGFlowHtmlParser:
    def __call__(self, fnm, binary=None, chunk_token_num=512):
        # 1. è§£æ HTML
        soup = BeautifulSoup(txt, "html5lib")
        
        # 2. æ¸…ç†æ— ç”¨æ ‡ç­¾
        for style_tag in soup.find_all(["style", "script"]):
            style_tag.decompose()
        
        # 3. é€’å½’æå–æ–‡æœ¬
        cls.read_text_recursively(soup.body, temp_sections, chunk_token_num)
        
        # 4. åˆå¹¶å’Œåˆ†æ®µ
        sections = cls.chunk_block(block_txt_list, chunk_token_num)
````

**è¯†åˆ«çš„ HTML æ ‡ç­¾**ï¼š
- **æ ‡é¢˜**ï¼šh1, h2, h3, h4, h5, h6
- **æ®µè½**ï¼šp, div, article, section, aside
- **åˆ—è¡¨**ï¼šul, ol, li
- **è¡¨æ ¼**ï¼štable
- **ä»£ç **ï¼špre, code, blockquote
- **å›¾ç‰‡**ï¼šfigure, figcaption

---

### 4ï¸âƒ£ **çŸ¥è¯†å›¾è°±æå–é…ç½®**

#### **å®Œæ•´é…ç½®ç¤ºä¾‹ï¼ˆé€šè¿‡ APIï¼‰**

```json
{
  "name": "ç½‘é¡µçŸ¥è¯†åº“",
  "chunk_method": "naive",
  "parser_config": {
    "chunk_token_num": 512,
    "delimiter": "\n!?ã€‚ï¼›ï¼ï¼Ÿ",
    "layout_recognize": "DeepDOC",
    "analyze_hyperlink": true,
    "graphrag": {
      "use_graphrag": true,
      "entity_types": ["ç»„ç»‡", "äººå‘˜", "åœ°ç†ä½ç½®", "äº‹ä»¶", "ç±»åˆ«"],
      "method": "light",
      "resolution": true,
      "community": true
    }
  }
}
```

#### **GraphRAG å‚æ•°è¯´æ˜**

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `use_graphrag` | boolean | `false` | æ˜¯å¦å¯ç”¨çŸ¥è¯†å›¾è°±æå– |
| `entity_types` | array | `["ç»„ç»‡", "äººå‘˜", ...]` | è¦æå–çš„å®ä½“ç±»å‹ |
| `method` | string | `"light"` | æå–æ–¹æ³•ï¼š`light` æˆ– `general` |
| `resolution` | boolean | `false` | æ˜¯å¦è¿›è¡Œå®ä½“æ¶ˆæ­§ |
| `community` | boolean | `false` | æ˜¯å¦è¿›è¡Œç¤¾åŒºæ£€æµ‹ |

---

### 5ï¸âƒ£ **è¶…é“¾æ¥åˆ†æåŠŸèƒ½**

Naive æ–¹æ³•æ”¯æŒ **è‡ªåŠ¨çˆ¬å–å’Œåˆ†æç½‘é¡µä¸­çš„è¶…é“¾æ¥**ï¼š

````python path=rag/app/naive.py mode=EXCERPT
if parser_config.get("analyze_hyperlink", False):
    # ä» DOCX æˆ– Markdown ä¸­æå–é“¾æ¥
    urls = extract_links_from_docx(binary)
    
    # é€’å½’çˆ¬å–æ¯ä¸ªé“¾æ¥çš„ HTML å†…å®¹
    for url in urls:
        html_bytes, metadata = extract_html(url)
        sub_url_res = chunk(url, html_bytes, ...)
        url_res.extend(sub_url_res)
````

**é…ç½®**ï¼š
```json
{
  "analyze_hyperlink": true  // å¯ç”¨è¶…é“¾æ¥åˆ†æ
}
```

---

### 6ï¸âƒ£ **å®Œæ•´å·¥ä½œæµç¨‹**

```mermaid
graph TD
    A[ä¸Šä¼  HTML æ–‡ä»¶] --> B[RAGFlowHtmlParser è§£æ]
    B --> C[æ¸…ç† style/script æ ‡ç­¾]
    C --> D[æå–æ–‡æœ¬å’Œè¡¨æ ¼]
    D --> E[æŒ‰ chunk_token_num åˆ†æ®µ]
    E --> F[å­˜å‚¨åˆ°çŸ¥è¯†åº“]
    F --> G{æ˜¯å¦å¯ç”¨ GraphRAG?}
    G -->|æ˜¯| H[ç‚¹å‡» Generate æŒ‰é’®]
    H --> I[é€‰æ‹© Knowledge Graph]
    I --> J[LLM æå–å®ä½“å’Œå…³ç³»]
    J --> K[æ„å»ºçŸ¥è¯†å›¾è°±]
    G -->|å¦| L[ä»…å­˜å‚¨æ–‡æœ¬åˆ†æ®µ]
```

---

## ğŸ¯ **æ¨èé…ç½®æ€»ç»“**

### **æ–¹æ¡ˆ 1ï¼šåŸºç¡€ç½‘é¡µçŸ¥è¯†åº“ï¼ˆæ— çŸ¥è¯†å›¾è°±ï¼‰**

```json
{
  "chunk_method": "naive",
  "parser_config": {
    "chunk_token_num": 512,
    "delimiter": "\n!?ã€‚ï¼›ï¼ï¼Ÿ",
    "layout_recognize": "DeepDOC"
  }
}
```

### **æ–¹æ¡ˆ 2ï¼šç½‘é¡µçŸ¥è¯†åº“ + çŸ¥è¯†å›¾è°±ï¼ˆæ¨èï¼‰**

```json
{
  "chunk_method": "naive",
  "parser_config": {
    "chunk_token_num": 512,
    "delimiter": "\n!?ã€‚ï¼›ï¼ï¼Ÿ",
    "layout_recognize": "DeepDOC",
    "analyze_hyperlink": true,
    "graphrag": {
      "use_graphrag": true,
      "entity_types": ["ç»„ç»‡", "äººå‘˜", "åœ°ç†ä½ç½®", "äº‹ä»¶", "ç±»åˆ«"],
      "method": "light",
      "resolution": true,
      "community": true
    }
  }
}
```

### **æ–¹æ¡ˆ 3ï¼šé•¿ç¯‡ç½‘é¡µæ–‡æ¡£ï¼ˆç±»ä¼¼ç”µå­ä¹¦ï¼‰**

```json
{
  "chunk_method": "book",
  "parser_config": {
    "chunk_token_num": 512,
    "delimiter": "\n!?ã€‚ï¼›ï¼ï¼Ÿ",
    "graphrag": {
      "use_graphrag": true,
      "entity_types": ["ç»„ç»‡", "äººå‘˜", "åœ°ç†ä½ç½®", "äº‹ä»¶", "ç±»åˆ«"],
      "method": "general"
    }
  }
}
```

---

## ğŸ“ **æ“ä½œæ­¥éª¤**

### **é€šè¿‡ UI é…ç½®**

1. åˆ›å»ºçŸ¥è¯†åº“æ—¶é€‰æ‹© **Naive** åˆ†æ®µæ–¹æ³•
2. é…ç½®å‚æ•°ï¼š
   - **Max Token Number**ï¼š512ï¼ˆé»˜è®¤ï¼‰
   - **Delimiter**ï¼š`\n!?ã€‚ï¼›ï¼ï¼Ÿ`
3. åœ¨ **GraphRAG** éƒ¨åˆ†ï¼š
   - å‹¾é€‰ **Enable GraphRAG**
   - è®¾ç½®å®ä½“ç±»å‹ï¼š`ç»„ç»‡, äººå‘˜, åœ°ç†ä½ç½®, äº‹ä»¶, ç±»åˆ«`
   - é€‰æ‹©æ–¹æ³•ï¼š**Light**ï¼ˆæ¨èï¼‰æˆ– **General**
4. ä¸Šä¼  HTML æ–‡ä»¶
5. ç­‰å¾…æ–‡ä»¶è§£æå®Œæˆ
6. ç‚¹å‡» **Generate** æŒ‰é’® â†’ é€‰æ‹© **Knowledge Graph**

### **é€šè¿‡ API é…ç½®**

```bash
curl -X POST "http://localhost:8080/api/v1/kb" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "ç½‘é¡µçŸ¥è¯†åº“",
    "chunk_method": "naive",
    "parser_config": {
      "chunk_token_num": 512,
      "delimiter": "\n!?ã€‚ï¼›ï¼ï¼Ÿ",
      "layout_recognize": "DeepDOC",
      "graphrag": {
        "use_graphrag": true,
        "entity_types": ["ç»„ç»‡", "äººå‘˜", "åœ°ç†ä½ç½®", "äº‹ä»¶", "ç±»åˆ«"],
        "method": "light"
      }
    }
  }'
```

---

## âš ï¸ **æ³¨æ„äº‹é¡¹**

1. **HTML æ–‡ä»¶ç¼–ç **ï¼šç¡®ä¿ HTML æ–‡ä»¶æ˜¯ UTF-8 ç¼–ç 
2. **æ–‡ä»¶å¤§å°**ï¼šå¤§å‹ç½‘é¡µå»ºè®®ä½¿ç”¨ `book` æ–¹æ³•
3. **è¶…é“¾æ¥çˆ¬å–**ï¼šå¯ç”¨ `analyze_hyperlink` ä¼šå¢åŠ å¤„ç†æ—¶é—´
4. **çŸ¥è¯†å›¾è°±ç”Ÿæˆ**ï¼šéœ€è¦æ‰‹åŠ¨è§¦å‘ï¼Œä¸æ˜¯è‡ªåŠ¨çš„
5. **LLM æˆæœ¬**ï¼šçŸ¥è¯†å›¾è°±æå–ä¼šæ¶ˆè€—å¤§é‡ LLM tokens
