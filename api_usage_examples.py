#!/usr/bin/env python3
"""
RAGFlow çŸ¥è¯†å›¾è°± API è°ƒç”¨å®ä¾‹
åŒ…å«åŸç”ŸAPIå’Œä¸­æ–‡åŒ–APIçš„å®Œæ•´ä½¿ç”¨ç¤ºä¾‹
"""

import requests
import json
from chinese_graph_api import ChineseGraphRAGAPI
from typing import Dict, List, Any

# é…ç½®ä¿¡æ¯
BASE_URL = "http://localhost:9380"
API_KEY = "ragflow-BlMGQyNzM0OTBhNzExZjA4MzU4ZGU3NW"
KB_ID = "dc949110906a11f08b78aa7cd3e67281"

def example_1_basic_api_calls():
    """ç¤ºä¾‹1ï¼šåŸºç¡€APIè°ƒç”¨"""
    print("=" * 60)
    print("ğŸ“‹ ç¤ºä¾‹1ï¼šåŸºç¡€APIè°ƒç”¨")
    print("=" * 60)
    
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    
    # 1. è·å–æ•°æ®é›†åˆ—è¡¨
    print("\n1ï¸âƒ£ è·å–æ•°æ®é›†åˆ—è¡¨")
    response = requests.get(f"{BASE_URL}/api/v1/datasets", headers=headers)
    datasets = response.json()
    
    print(f"çŠ¶æ€ç : {response.status_code}")
    print(f"æ•°æ®é›†æ•°é‡: {len(datasets.get('data', []))}")
    
    if datasets.get('data'):
        dataset = datasets['data'][0]
        print(f"æ•°æ®é›†åç§°: {dataset['name']}")
        print(f"æ•°æ®é›†ID: {dataset['id']}")
        print(f"æ–‡æ¡£æ•°é‡: {dataset['document_count']}")
        print(f"åˆ†å—æ•°é‡: {dataset['chunk_count']}")
    
    # 2. è·å–çŸ¥è¯†å›¾è°±ï¼ˆåŸå§‹è‹±æ–‡ç‰ˆæœ¬ï¼‰
    print("\n2ï¸âƒ£ è·å–çŸ¥è¯†å›¾è°±ï¼ˆåŸå§‹ç‰ˆæœ¬ï¼‰")
    response = requests.get(f"{BASE_URL}/api/v1/datasets/{KB_ID}/knowledge_graph", headers=headers)
    graph_data = response.json()
    
    if graph_data.get('data'):
        nodes = graph_data['data']['graph']['nodes']
        edges = graph_data['data']['graph']['edges']
        
        print(f"èŠ‚ç‚¹æ•°é‡: {len(nodes)}")
        print(f"è¾¹æ•°é‡: {len(edges)}")
        
        # æ˜¾ç¤ºå‰2ä¸ªèŠ‚ç‚¹ï¼ˆè‹±æ–‡ç‰ˆæœ¬ï¼‰
        print("\nğŸ“Š åŸå§‹èŠ‚ç‚¹ç¤ºä¾‹ï¼ˆè‹±æ–‡ï¼‰:")
        for i, node in enumerate(nodes[:2]):
            print(f"  èŠ‚ç‚¹{i+1}:")
            print(f"    åç§°: {node['entity_name']}")
            print(f"    ç±»å‹: {node['entity_type']} (è‹±æ–‡)")
            print(f"    é‡è¦æ€§: {node.get('pagerank', 0):.3f}")
            print(f"    æ¥æºæ–‡ä»¶æ•°: {len(node.get('source_id', []))}")

def example_2_chinese_api():
    """ç¤ºä¾‹2ï¼šä¸­æ–‡åŒ–APIè°ƒç”¨"""
    print("\n" + "=" * 60)
    print("ğŸ‡¨ğŸ‡³ ç¤ºä¾‹2ï¼šä¸­æ–‡åŒ–APIè°ƒç”¨")
    print("=" * 60)
    
    # åˆ›å»ºä¸­æ–‡åŒ–APIå®ä¾‹
    chinese_api = ChineseGraphRAGAPI(BASE_URL, API_KEY)
    
    # 1. è·å–ä¸­æ–‡åŒ–çŸ¥è¯†å›¾è°±
    print("\n1ï¸âƒ£ è·å–ä¸­æ–‡åŒ–çŸ¥è¯†å›¾è°±")
    chinese_graph = chinese_api.get_chinese_knowledge_graph(KB_ID)
    
    if 'error' not in chinese_graph:
        nodes = chinese_graph['data']['graph']['nodes']
        edges = chinese_graph['data']['graph']['edges']
        
        print(f"âœ… æˆåŠŸè·å–ä¸­æ–‡åŒ–å›¾è°±")
        print(f"èŠ‚ç‚¹æ•°é‡: {len(nodes)}")
        print(f"è¾¹æ•°é‡: {len(edges)}")
        
        # æ˜¾ç¤ºå‰3ä¸ªèŠ‚ç‚¹ï¼ˆä¸­æ–‡ç‰ˆæœ¬ï¼‰
        print("\nğŸ“Š ä¸­æ–‡åŒ–èŠ‚ç‚¹ç¤ºä¾‹:")
        for i, node in enumerate(nodes[:3]):
            print(f"  èŠ‚ç‚¹{i+1}:")
            print(f"    åç§°: {node['entity_name']}")
            print(f"    ç±»å‹: {node['entity_type']} (ä¸­æ–‡)")
            print(f"    è‹±æ–‡ç±»å‹: {node.get('entity_type_en', 'N/A')}")
            print(f"    é‡è¦æ€§: {node.get('pagerank', 0):.3f}")
            print(f"    æ¥æºæ–‡ä»¶æ•°: {node['source_files_count']}")
            print(f"    æœ‰æºæ–‡ä»¶: {'æ˜¯' if node['has_source_files'] else 'å¦'}")
            print()
    
    # 2. è·å–å®ä½“ç»Ÿè®¡
    print("2ï¸âƒ£ è·å–å®ä½“ç»Ÿè®¡ä¿¡æ¯")
    stats = chinese_api.get_entity_statistics(KB_ID)
    
    if 'error' not in stats:
        print(f"âœ… ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  æ€»èŠ‚ç‚¹æ•°: {stats['total_nodes']}")
        print(f"  æ€»è¾¹æ•°: {stats['total_edges']}")
        print(f"  æ–‡ä»¶è¦†ç›–ç‡: {stats['coverage_rate']}")
        print(f"  æœ‰æºæ–‡ä»¶çš„èŠ‚ç‚¹: {stats['nodes_with_source_files']}")
        
        print("\nğŸ“ˆ å®ä½“ç±»å‹åˆ†å¸ƒ:")
        for entity_type, count in stats['entity_type_distribution'].items():
            percentage = (count / stats['total_nodes'] * 100) if stats['total_nodes'] > 0 else 0
            print(f"    {entity_type}: {count} ä¸ª ({percentage:.1f}%)")

def example_3_node_details():
    """ç¤ºä¾‹3ï¼šè·å–èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯"""
    print("\n" + "=" * 60)
    print("ğŸ” ç¤ºä¾‹3ï¼šè·å–èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯")
    print("=" * 60)
    
    chinese_api = ChineseGraphRAGAPI(BASE_URL, API_KEY)
    
    # å…ˆè·å–ä¸€äº›èŠ‚ç‚¹
    graph_data = chinese_api.get_chinese_knowledge_graph(KB_ID)
    if 'error' in graph_data:
        print(f"âŒ é”™è¯¯: {graph_data['error']}")
        return
    
    nodes = graph_data['data']['graph']['nodes']
    
    # é€‰æ‹©å‡ ä¸ªæœ‰ä»£è¡¨æ€§çš„èŠ‚ç‚¹
    test_nodes = [
        "å¦é—¨å›½è´¸è‚¡ä»½æœ‰é™å…¬å¸",
        "è´¢åŠ¡éƒ¨", 
        "é»„å‘å"
    ]
    
    for node_name in test_nodes:
        print(f"\nğŸ” æŸ¥è¯¢èŠ‚ç‚¹: {node_name}")
        node_info = chinese_api.get_node_source_info(KB_ID, node_name)
        
        if 'error' not in node_info:
            print(f"âœ… èŠ‚ç‚¹è¯¦æƒ…:")
            print(f"  åç§°: {node_info['node_name']}")
            print(f"  ç±»å‹: {node_info['node_type']}")
            print(f"  è‹±æ–‡ç±»å‹: {node_info['node_type_en']}")
            print(f"  é‡è¦æ€§è¯„åˆ†: {node_info['pagerank']:.3f}")
            print(f"  æºæ–‡ä»¶æ•°é‡: {node_info['source_files_count']}")
            print(f"  æºæ–‡ä»¶ID: {node_info['source_ids'][:2]}..." if len(node_info['source_ids']) > 2 else f"  æºæ–‡ä»¶ID: {node_info['source_ids']}")
            
            # æ˜¾ç¤ºæè¿°çš„å‰100ä¸ªå­—ç¬¦
            description = node_info.get('description', '')
            if description:
                print(f"  æè¿°: {description[:100]}...")
        else:
            print(f"âŒ æœªæ‰¾åˆ°èŠ‚ç‚¹: {node_info['error']}")

def example_4_search_and_filter():
    """ç¤ºä¾‹4ï¼šæœç´¢å’Œç­›é€‰å®ä½“"""
    print("\n" + "=" * 60)
    print("ğŸ” ç¤ºä¾‹4ï¼šæœç´¢å’Œç­›é€‰å®ä½“")
    print("=" * 60)
    
    chinese_api = ChineseGraphRAGAPI(BASE_URL, API_KEY)
    
    # è·å–å®Œæ•´å›¾è°±ç”¨äºç­›é€‰
    graph_data = chinese_api.get_chinese_knowledge_graph(KB_ID)
    if 'error' in graph_data:
        print(f"âŒ é”™è¯¯: {graph_data['error']}")
        return
    
    nodes = graph_data['data']['graph']['nodes']
    
    # 1. æŒ‰å®ä½“ç±»å‹ç­›é€‰
    print("\n1ï¸âƒ£ æŒ‰å®ä½“ç±»å‹ç­›é€‰")
    entity_types = ["ç»„ç»‡", "äººå‘˜", "äº‹ä»¶"]
    
    for entity_type in entity_types:
        filtered_nodes = [node for node in nodes if node.get('entity_type') == entity_type]
        print(f"\nğŸ“‹ {entity_type}ç±»å®ä½“ (å…±{len(filtered_nodes)}ä¸ª):")
        
        # æŒ‰é‡è¦æ€§æ’åºï¼Œæ˜¾ç¤ºå‰5ä¸ª
        top_nodes = sorted(filtered_nodes, key=lambda x: x.get('pagerank', 0), reverse=True)[:5]
        for i, node in enumerate(top_nodes):
            print(f"  {i+1}. {node['entity_name']} (é‡è¦æ€§: {node.get('pagerank', 0):.3f})")
    
    # 2. æŒ‰å…³é”®è¯æœç´¢
    print("\n2ï¸âƒ£ æŒ‰å…³é”®è¯æœç´¢")
    keywords = ["è´¢åŠ¡", "å®‰å…¨", "å®¡æ‰¹"]
    
    for keyword in keywords:
        matching_nodes = [
            node for node in nodes 
            if keyword in node.get('entity_name', '') or keyword in node.get('description', '')
        ]
        
        print(f"\nğŸ” åŒ…å«'{keyword}'çš„å®ä½“ (å…±{len(matching_nodes)}ä¸ª):")
        for i, node in enumerate(matching_nodes[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"  {i+1}. {node['entity_name']} ({node['entity_type']})")
    
    # 3. æŒ‰æ–‡ä»¶æ¥æºç­›é€‰
    print("\n3ï¸âƒ£ æŒ‰æ–‡ä»¶æ¥æºç­›é€‰")
    
    # æ‰¾å‡ºæ¥æºæ–‡ä»¶æœ€å¤šçš„å®ä½“
    nodes_with_files = [node for node in nodes if node.get('source_files_count', 0) > 0]
    top_file_nodes = sorted(nodes_with_files, key=lambda x: x.get('source_files_count', 0), reverse=True)[:5]
    
    print(f"\nğŸ“ æ¥æºæ–‡ä»¶æœ€å¤šçš„å®ä½“:")
    for i, node in enumerate(top_file_nodes):
        print(f"  {i+1}. {node['entity_name']} - {node['source_files_count']} ä¸ªæ–‡ä»¶ ({node['entity_type']})")

def example_5_relationship_analysis():
    """ç¤ºä¾‹5ï¼šå…³ç³»åˆ†æ"""
    print("\n" + "=" * 60)
    print("ğŸ”— ç¤ºä¾‹5ï¼šå…³ç³»åˆ†æ")
    print("=" * 60)
    
    chinese_api = ChineseGraphRAGAPI(BASE_URL, API_KEY)
    
    graph_data = chinese_api.get_chinese_knowledge_graph(KB_ID)
    if 'error' in graph_data:
        print(f"âŒ é”™è¯¯: {graph_data['error']}")
        return
    
    nodes = graph_data['data']['graph']['nodes']
    edges = graph_data['data']['graph']['edges']
    
    # 1. å…³ç³»ç±»å‹ç»Ÿè®¡
    print("\n1ï¸âƒ£ å…³ç³»ç±»å‹ç»Ÿè®¡")
    relation_stats = {}
    for edge in edges:
        relation = edge.get('description', 'æœªçŸ¥å…³ç³»')[:20]  # å–å‰20ä¸ªå­—ç¬¦
        relation_stats[relation] = relation_stats.get(relation, 0) + 1
    
    # æ˜¾ç¤ºæœ€å¸¸è§çš„å…³ç³»ç±»å‹
    top_relations = sorted(relation_stats.items(), key=lambda x: x[1], reverse=True)[:5]
    print("ğŸ“Š æœ€å¸¸è§çš„å…³ç³»ç±»å‹:")
    for relation, count in top_relations:
        print(f"  {relation}: {count} æ¬¡")
    
    # 2. èŠ‚ç‚¹è¿æ¥åº¦åˆ†æ
    print("\n2ï¸âƒ£ èŠ‚ç‚¹è¿æ¥åº¦åˆ†æ")
    node_connections = {}
    
    for edge in edges:
        source = edge['source']
        target = edge['target']
        
        node_connections[source] = node_connections.get(source, 0) + 1
        node_connections[target] = node_connections.get(target, 0) + 1
    
    # æ‰¾å‡ºè¿æ¥åº¦æœ€é«˜çš„èŠ‚ç‚¹
    top_connected = sorted(node_connections.items(), key=lambda x: x[1], reverse=True)[:5]
    print("ğŸŒŸ è¿æ¥åº¦æœ€é«˜çš„èŠ‚ç‚¹:")
    for node_id, connections in top_connected:
        # æ‰¾åˆ°å¯¹åº”çš„èŠ‚ç‚¹ä¿¡æ¯
        node_info = next((n for n in nodes if n['id'] == node_id), None)
        if node_info:
            print(f"  {node_info['entity_name']} ({node_info['entity_type']}): {connections} ä¸ªè¿æ¥")
    
    # 3. ç‰¹å®šèŠ‚ç‚¹çš„å…³ç³»ç½‘ç»œ
    print("\n3ï¸âƒ£ ç‰¹å®šèŠ‚ç‚¹çš„å…³ç³»ç½‘ç»œ")
    target_node = "å¦é—¨å›½è´¸è‚¡ä»½æœ‰é™å…¬å¸"
    
    related_edges = [edge for edge in edges if edge['source'] == target_node or edge['target'] == target_node]
    
    print(f"ğŸ¢ '{target_node}' çš„å…³ç³»ç½‘ç»œ:")
    print(f"  ç›´æ¥å…³ç³»æ•°: {len(related_edges)}")
    
    # æ˜¾ç¤ºå‰5ä¸ªå…³ç³»
    for i, edge in enumerate(related_edges[:5]):
        if edge['source'] == target_node:
            other_node = edge['target']
            direction = "â†’"
        else:
            other_node = edge['source']
            direction = "â†"
        
        # æ‰¾åˆ°å¯¹æ–¹èŠ‚ç‚¹çš„ç±»å‹
        other_node_info = next((n for n in nodes if n['id'] == other_node), None)
        other_type = other_node_info['entity_type'] if other_node_info else 'æœªçŸ¥'
        
        print(f"  {i+1}. {direction} {other_node} ({other_type})")

def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸš€ RAGFlow çŸ¥è¯†å›¾è°± API è°ƒç”¨å®ä¾‹")
    print("åŒ…å«åŸç”ŸAPIå’Œä¸­æ–‡åŒ–APIçš„å®Œæ•´ä½¿ç”¨ç¤ºä¾‹")
    
    try:
        # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
        example_1_basic_api_calls()
        example_2_chinese_api()
        example_3_node_details()
        example_4_search_and_filter()
        example_5_relationship_analysis()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™: {str(e)}")
        print("è¯·æ£€æŸ¥ï¼š")
        print("1. RAGFlow æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
        print("2. API å¯†é’¥æ˜¯å¦æ­£ç¡®")
        print("3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("4. chinese_graph_api.py æ–‡ä»¶æ˜¯å¦å­˜åœ¨")

if __name__ == "__main__":
    main()
